# TCP和UDP的区别和应用场景
UDP：无连接的，尽最大努力交付，面向报文的，没有拥塞控制和流量控制，支持一对一，一对多，多对一和多对多的交互通信，传输协议比较简单，实时性和工作效率较高
TCP:  面向连接的，提供可靠交付，面向字节流，只支持一对一通信，提供全双工通信；
适用场景：
* TCP:
**对数据传输的质量有较高要求，但对实时性要求不高。比如HTTP，HTTPS，FTP等传输文件的协议以及POP，SMTP等邮件传输的协议，应选用TCP协议。**
UDP:
**只对数据传输的实时性要求较高，但不对传输质量有要求。比如视频传输、实时通信等，应选用UDP协议**
# TCP如何保证可靠传输
* 校验和
发送的数据包的二进制相加然后取反，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。
* 确认应答+序列号TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
* 超时重传
当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
* 流量控制
TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。接收方有即时窗口（滑动窗口），随ACK报文发送![5e1267ff2ed886b36ddbbaaf2ac1713b.png](en-resource://database/1168:2)
当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。

* 拥塞控制
当网络拥塞时，减少数据的发送。发送方有拥塞窗口，发送数据前比对接收方发过来的即使窗口，取小
# UDP如何实现TCP可靠传输
因为UDP是无连接的协议，所以在传输层上无法保证可靠传输，要想实现可靠传输，只能从应用层实现。需要实现seq/ack机制，重传机制和窗口确认机制。就要接收方收到UDP之后回复个确认包，发送方有个机制，收不到确认包就要重新发送，每个包有递增的序号，接收方发现中间丢了包就要发重传请求，当网络太差时候频繁丢包，防止越丢包越重传的恶性循环，要有个发送窗口的限制，发送窗口的大小根据网络传输情况调整，调整算法要有一定自适应性。
# 端口的作用是什么
端口的作用是对TCP/IP体系的应用进程进行统一的标志，使运行不同操作系统的计算机的应用进程能够相互通信。

# Mac地址与IP地址区别
一、地址性质不同
MAC地址是物理地址，IP地址是逻辑地址。MAC地址工作在数据链路层，IP地址工作在网络层，是给每个连接在因特网的主机分配一个在全世界范围内唯一的标识符，从而可以把整个因特网看成一个单一的抽象的网络。
二、地址长度不同
1. mac地址的长度为48位（6个字节），通常表示为12个16进制数，每2个16进制数之间用冒号隔开
2.ip地址为32位，由用点分隔开的4个8位组构成，如192.168.0.1就是一个ip地址，这种写法叫点分十进制格式。
3.分配依据不同
1.MAC地址的分配是由网络设备制造商生产时写在硬件内部。这个地址与网络无关，也就是说无论将带有这个地址的硬件（如集线器、网卡、路由器等）接入到网络的何处，他都有相同的MAC地址，是不可变的
2.IP地址的分配是基于网络拓补
IP地址由网络地址和主机地址两部分组成，分配给这两部分的位数随地址类（A类、B类、C类）的不同而不同。
# ARP解析过程
网络层使用的是IP地址，但实际网络的链路上传送数据帧时，最终还是使用该网络的硬件地址，ARP协议主要解决的就是知道了一个机器的IP地址如何寻找他的硬件地址。
每一个主机都设有一个ARP高速缓存，里面有本局域网上的各主机和路由器的IP地址到硬件地址的映射表，当主机A要向本局域网的主机B发送数据报时，首先在ARP告诉缓存中查找有无对应的主机B的IP地址，如果有就在ARP高速缓存中找出其对应的硬件地址，再把该硬件地址写入MAC帧，通过局域网把该MAC帧发往此硬件地址；如果没有查到主机B的IP地址项目，主机A就自动进行ARP，ARP进程向本局域网发送ARP请求分组，请求分组的主要内容是：“我的IP地址是多少，我的硬件地址是多少，想知道IP地址是多少的硬件地址。”本局域网所有的主机上运行的ARP进程都会收到此ARP请求分组，如果主机B的ip地址与请求分组想要查询的IP地址一致，就向主机A发送自己的ARP响应分组，响应分组的内容是“我的ip地址是多少，我的硬件地址是多少”响应分组单播，同时也会把主机A的IP地址和硬件地址的映射存入自己的ARP高速缓存，如果主机的IP地址与ARP请求分组的IP地址不一致，则不理睬这个请求分组。主机A收到响应分组就在ARP缓存中写入主机B的IP地址到硬件地址的映射。
ARP把保存在高速缓存中的每一个映射地址项目都设置一个生存时间，解决局域网上主机硬件地址的可能发生变化的情况。
# DNS原理
![5d73cba92c25aca532b46388a3aeb81c.png](en-resource://database/1162:1)
一、主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的IP地址，那么本地域名服务器就以DNS客户的身份，向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的IP地址，或者是报错，表示无法查询到所需的IP地址。
二、本地域名服务器向根域名服务器的查询通常是采用迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询（而不是替本地域名服务器进行后续查询）。根域名服务器通常是把自己知道的顶级域名服务器的IP地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的IP地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，知道了所要解析的IP地址或报错，然后把这个结果返回给发起查询的主机
为了提高DNS查询效率，并减轻根域名服务器的负荷和减少因特网上DNS查询报文的数量，在域名服务器中广泛的使用了高速缓存，高速缓存用来存放最近查询过的域名以及从何处获得域名映射信息的记录。实际解析过程中，
1、若没有，则搜索操作系统中的DNS缓存（维护一张域名与IP地址的对应表）；　　
2、若没有，则搜索操作系统的hosts文件（Windows环境下，维护一张域名与IP地址的对应表）；　　
3、若没有，则操作系统将域名发送至本地域名服务器---（递归查询方式），本地域名服务器查询自己的DNS缓存，查找成功则返回结果，否则，（以下是迭代查询方式）　　　　
    3.1. 本地域名服务器向根域名服务器（其虽然没有每个域名的具体信息，但存储了负责每个域，如com、net、org等解析的顶级域名服务器的地址）发起请求，此处，根域名服务器返回com域的顶级域名服务器的地址；　　　　
    3.2. 本地域名服务器向com域的顶级域名服务器发起请求，返回baidu.com权限域名服务器（权限域名服务器，用来保存该区中的所有主机域名到IP地址的映射）地址；　　　　
    3.3. 本地域名服务器向baidu.com权限域名服务器发起请求，得到www.baidu.com的IP地址；　　
4、本地域名服务器将得到的IP地址返回给操作系统，同时自己也将IP地址缓存起来；　　
5、操作系统将IP地址返回给浏览器，同时自己也将IP地址缓存起来；　　
6、至此，浏览器已经得到了域名对应的IP地址；
# HTTP状态码
![6185f03e0cf03607bea6bda2747fd630.png](en-resource://database/1163:1)
![10f96eac1753f9879864a99d7df95b79.png](en-resource://database/1130:1)
# 原理 
HTTP协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。
# 一次完整的HTTP请求过程
* 域名解析
* 为了将消息从客户端上传到服务器，需要用到IP协议，ARP协议和OSPF协议
* 发起TCP的三次握手，建立TCP连接
* 建立TCP连接后发起HTTP请求
* 服务器响应HTTP请求
* 浏览器解析html代码，并请求HTML代码中的资源
* 断开TCP连接
* 浏览器对页面进行渲染呈现给用户
# UDP首部格式
![64f2aa47ab5b3aa12234d390f2b5e883.png](en-resource://database/1171:1)
# TCP首部格式
![55a91b40eedf984dea3ce67d72d02858.png](en-resource://database/1167:1)
![167107c791c9876a9f5519d01a309498.png](en-resource://database/1164:1)
# TCP三次握手、四次挥手*
**刚开始客户端处于 closed 的状态，服务端处于 listen 状态**。然后
      1、第一次握手：客户端给服务端发一个 连接请求报文，此时SYN=1,ACK=0,初始化序列号 x。此时客户端处于 SYN_Send 状态。
      2、第二次握手：服务器收到客户端的连接请求报文之后，如果同意建立连接，会向客户端发送连接确认报文段，SYN=1,ACK=1,确认号为x=1,并且也是指定了自己的初始化序列号 y,此时服务器处于 SYN_REVD 的状态。
      3、第三次握手：客户端收到连接确认报文之后，还会向服务器发送确认，确认号为y+1，序列号为x+1,此时客户端处于 establised 状态。
      4、服务器收到 ACK 报文之后，也处于 establised 状态，此时，双方以建立起了链接。

* 三次握手的作用
1、确认双方的接受能力、发送能力是否正常。      
2、指定自己的初始化序列号，为后面的可靠传送做准备。     
3、如果是 https 协议的话，三次握手这个过程，还会进行数字证书的验证以及加密密钥的生成到。
4. 防止失效的连接请求到达服务器，让服务器错误打开连接
* 三次握手过程中可以携带数据吗
第一次第二次不可以，其实第三次握手的时候，是可以携带数据的。也就是说，第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。
假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，其中一个简单的原因就是会让服务器更加容易受到攻击了。
而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。
* 四次挥手
![d799ccfcf2690e3480252b8b0a89fa14.png](en-resource://database/1174:1)
 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：
      1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。
      2、第二次握手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。
      3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。
      4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态
      5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。
![a22c7cd5c117ee70e5bf0435ac1e2b5e.png](en-resource://database/1173:1)
# 服务器出现大量close_wait的连接的原因以及解决方法
close_wait状态是在TCP四次挥手的时候收到FIN但是没有发送自己的FIN时出现的，服务器出现大量close_wait状态的原因有两种：

* 服务器内部业务处理占用了过多时间，都没能处理完业务；或者还有数据需要发送；或者服务器的业务逻辑有问题，没有执行close()方法
* 服务器的父进程派生出子进程，子进程继承了socket，收到FIN的时候子进程处理但父进程没有处理该信号，导致socket的引用不为0无法回收
**处理方法：**

* 停止应用程序
* 修改程序里的bug

# TCP状态转换
![43ae6472cbb15ad5811e620f651f8a03.png](en-resource://database/1166:1)
# TCP状态中TIME_WAIT
2MSL,2个报文段最大生存时间
![5f68530991433eebc9964a01fde3501a.png](en-resource://database/1170:1)
# TCP第三次握手失败会出现什么
当第三次握手失败时，服务器并不会重传ack报文，而是直接发送RST报文段，进入closed状态，这样做的目的是为了防止SYN洪泛攻击。
# TCP长连接和短链接及优缺点
![5ef51afaa731ed3f04dd9e79f590254a.png](en-resource://database/1169:1)
![69af7116846b98ccb4608b2e627b17ba.png](en-resource://database/1172:1)
![2f6c1c22e7c4c49a12a02c50be1cb85b.png](en-resource://database/1165:1)
# TCP拥塞控制-慢启动、拥塞避免、快重传、快启动
1. 慢开始
慢启动算法的思路是当主机开始发送数据时，先以比较小的拥塞窗口进行发送，然后每次翻倍，也就是说，由小到大逐渐增加拥塞窗口的大小，而这个大小是指数增长的，即1、2、4、8、16为了防止拥塞窗口cwnd增长过大引起网络拥塞，还要另外设置一个慢启动阈值ssthresh状态变量，当拥塞窗口的大小超过慢启动阈值的时候（ cwnd > ssthresh 时），停止使用慢开始算法而改用拥塞避免算法
2. 拥塞避免
拥塞避免算法的思路是让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。
3. 快速重传
快重传算法首先要求接受方每收到一个失序的报文段就立即发出重复确认，快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。
4. 快速恢复
当发送方连续收到三个重复确认后，就把慢开始门限减半，这是预防网络发生拥塞
但接下来不执行慢开始算法，由于发送方认为现在还没有发生拥塞，如果发生严重拥塞，就不会有连续好几个报文段连续到达接受方，因此与慢开始算法不同之初是把拥塞窗口的值设置为慢开始门限的一半，开始执行拥塞避免算法。
# TCP如何解决粘包、拆包问题
因为TCP是面向流，没有边界，所以接收端在一次接收的时候有可能一次接收多个包。而TCP粘包就是发送方的若干个数据包到达接收方的时候粘成了一个包。多个包首尾相接，无法区分。
如果一次请求发送的数据量比较小，没达到缓冲区大小，TCP则会将多个请求合并为同一个请求进行发送，这就形成了粘包问题。
如果一次请求发送的数据量比较大，超过了缓冲区大小，TCP就会将其拆分为多次发送，这就是拆包。
导致TCP粘包的原因有三方面：
* 发送端等待缓冲区满才进行发送，造成粘包
* 接收方来不及接收缓冲区内的数据，造成粘包
* 由于TCP协议在发送较小的数据包的时候，会将几个包合成一个包后发送
![5e1267ff2ed886b36ddbbaaf2ac1713b.png](en-resource://database/1168:2)
# 滑动窗口

* TCP 利用滑动窗口实现流量控制的机制。
* TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。
* 流量控制TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。、

# 1.Q：什么是TCP粘包问题？
TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。
# 2.Q：造成TCP粘包的原因
（1）发送方原因TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

    1. 只有上一个分组得到确认，才会发送下一个分组收集多个小分组，在一个确认到来时一起发送Nagle算法造成了发送方可能会出现粘包问题
（2）接收方原因TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。
# 3.Q：什么时候需要处理粘包现象？
如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象了
# 4.Q：如何处理粘包现象？
（1）发送方对于发送方造成的粘包问题，可以通过关闭Nagle算法来解决，使用TCP_NODELAY选项来关闭算法。
（2）接收方接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。
（3）应用层应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。
解决办法：**循环处理，**应用程序从接收缓存中读取分组时，读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成，但是如何判断每条数据的长度呢？
**格式化数据：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。**
**发送长度：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。**
5.Q：UDP会不会产生粘包问题呢？
TCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的（保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息）。UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题。
# HTTP与HTTPS
超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。而HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。
# HTTPS和HTTP的区别主要如下：
1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。
2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。
3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。
# HTTPS在客户端和web服务器之间通信时的步骤
（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。
（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。
（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。
（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。
（5）Web服务器利用自己的私钥解密出会话密钥。
（6）web服务器利用会话密钥加密与客户端之间的通信。
# HTTPS安全性保证
* 对称加密
    * 加密和解密使用的密钥是同一个
    * 优点：计算量小，算法速度快，加密效率高 缺点：密钥容易泄漏。不同的会话需要不同的密钥，管理起来很费劲   
非对称加密：

    * 需要公钥和私钥，公钥用来加密，私钥用来解密
    *  常用算法：RSA，ECC，DSA   

*  **数字签名**：
作用：保证数据的完整性，不被篡改或破坏
生成过程：先对将要传输的信息进行hash，得到一串独一无二的字符，通常把hash之后的内容称为信息摘要message digest，
hash是不可逆的无法根据信息摘要推测出原文，不同的原文，会造成不同的hash结果，并且结果的差异是巨大甚至毫无规律的，。
用自己的私钥进行加密，得到数字签名。
接受方先用公钥进行解密，之后将信息原文进行哈希得到自己hash的信息摘要，再与数字签名解码得到的hash摘要进行比较，如果相同说明原文信息是完整的。
* **数字证书**：
作用：保证公钥没有没伪造
数字证书机构使用私钥将网站A的信息和消息摘要（签名S）进行加密打包形成数字证书。浏览器使用数字证书机构的公钥解密后得到真实服务器的公钥。这个过程是建立在被大家所认可的证书机构之上得到的公钥，所以这是一种安全的方式。
# 状态码
![fbccc3b2ee4bd6db0bdab300bb5b4678.png](en-resource://database/1224:1)
# http1.0与http1.1
* 长连接
HTTP1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启长连接keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。
* 节约带宽
HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。
* HOST域
在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname），HTTP1.0没有host域。随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都支持host域，且请求消息中如果没有host域会报告一个错误

# http1.1与http2.0
* 多路复用
HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。
* 头部数据压缩
在HTTP1.1中，HTTP请求和响应都是由状态行、请求/响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。
* 服务器推送
服务端推送是一种在客户端请求之前发送数据的机制。