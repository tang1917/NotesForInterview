# 零拷贝

主要任务是避免CPU将数据从一块存储拷贝到另一块存储， **内核缓冲区和用户缓冲区之间的的数据拷贝，称为零拷贝**

## DMA（直接存储器访问）

指外部设备不通过CPU而直接而直接与系统内存交换数据的接口技术

## 将服务器端主机磁盘文件中的文件不做修改地从已连接的文件中发送出去

1. 将磁盘上的数据拷贝到内核缓冲区（主要依靠DMA来实现）
2. 再把内核缓冲区的内容拷贝到用户缓冲区
3. 用户缓冲区的内容拷贝到socket缓冲区
4. socket缓冲区的内容发送到网卡

## mmap()函数

应用程序调用mmap()，磁盘上的数据通过DMA拷贝到内核缓冲区，接着操作系统会把这段内核缓冲区与应用程序共享，这样就不需要把内核缓冲区的内容往用户空间拷贝。应用程序再调用write(),操作系统直接将内核缓冲区的内容拷贝到socket缓冲区，这一切都发生在内核态。

## 可能出现的问题

**当程序mmap了一个文件，但是当这个文件被另一个进程截断时，write系统调用会因为访问非法地址而被SIGBUS信号终止。**

sendfile()

splice（）

# 用户缓冲区、内核缓冲区

## 用户缓冲区

* 一些程序在读取文件时，会先申请一块内存数组，称为buffer，然后每次调用read，读取设定字节长度的数据，写入buffer。（用较小的次数填满buffer）。之后的程序都是从buffer中获取数据，当buffer使用完后，在进行下一次调用，填充buffe
* 作用：`减少系统调用次数，从而降低操作系统在用户态与核心态切换所耗费的时间`。

## 内核缓冲区

当一个用户进程要从磁盘读取数据时，内核一般不直接读磁盘，而是将内核缓冲区中的数据复制到进程缓冲区中。若是内核缓冲区中没有数据，内核会把对数据块的请求，加入到请求队列，然后把进程挂起，为其它进程提供服务

等到数据已经读取到内核缓冲区时，把内核缓冲区中的数据读取到用户进程中，才会通知进程

* **read是把数据从内核缓冲区复制到进程缓冲区。write是把进程缓冲区复制到内核缓冲区。**

## socket缓冲区

* 当某个应用进程调用套接字的write方法时，会先将数据写入该应用进程的缓冲区，此后内核会从该应用进程的缓冲区复制所有数据到要写的套接字的发送缓冲区

* 如果该套接字的发送缓冲区容不下该应用进程的所有数据（或是应用进程的缓冲区大于套接字的发送缓冲区，或是套接字的发送缓冲区中已有其他数据）， 该应用进程则无法继续写入自身的缓冲区，此时将会被阻塞住。内核将不从write系统调用返回，直到应用进程缓冲区中的所有数据都复制到套接字发送缓冲区
* 如果调用TCP套接字的write方法并成功返回时，仅仅能代表我们可以重新使用原来的应用进程缓冲区，并不表明对端的TCP或应用进程已接收到数据，数据可能还在TCP的发送缓冲区中



# socket可读可写情况

* 可读
  * 内核接收缓冲区中的字节数大于或等于其低水位标记
  * socket通信的对方关闭连接，此时对该socket的读操作将返回0
  * 监听socket上有新的连接请求
  * socket上有未处理的错误
* 可写
  * 发送缓存区可用字节数大于或等于其低水位标记
  * socket的写操作被关闭
  * socket使用非阻塞connect连接成功或者失败（超时）之后
  * socket上有未处理的错误

# ps命令

-A:列出所有的进程

-aux:显示所有包含其他使用者的进程

r:显示当前终端的进程

USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND

-f 进程之间的关系

# TOP命令

**提供实时的系统处理器的状态监**视，它是一个动态的显示过程

* 第一行显示内容：

当前时间，系统运行时间，当前登录用户数，系统负载

* 第二行显示内容

进程总数，正在运行数，睡眠的进程数，停止的进程数，僵尸进程数

* 第三行

用户空间占用cpu百分比，内核空间占用cpu百分比，用户进程空间内改变过优先级的进程占用cpu百分比，空闲cpu占用百分比

* 第四、五行

物理内存总量，使用的物理内存总量，空闲内存总量，用作内核缓存的内存量

* 进程信息

进程id，进程所有者的用户名，

# linux进程有几种状态，如何查看

ps top

# Linux内存分布

* 内核空间
* 栈
* 堆
* 未初始化的数据
* 初始化的数据
* 程序段

# 代理服务器

在HTTP通信链上，客户端和目标服务器之间通常存在某些中转代理服务器，它们提供对目标资源的中转访问。按照代理服务器使用方式和作用，分为正向代理服务器，反向代理服务器和透明代理服务器。

* 正向代理要求客户端自己设置代理服务器的地址。客户的每次请求直接发送到该代理服务器，并由代理服务器来请求目标资源。
* 反向代理服务器被设置在服务端，因为客户无序进行任何设置。反向代理是指用代理服务器来接受internet上的连接请求，然后将连接请求转发给内部网络上的服务器。
* Nginx 是一个很强大的高性能[Web](https://baike.baidu.com/item/Web/150564)和[反向代理](https://baike.baidu.com/item/反向代理)服务，它具有很多非常优越的特性

# 设计秒杀系统

## 系统的特点

* 高性能：秒杀涉及大量的并发读和并发写，因此支持高并发访问这点非常关键
* 一致性：秒杀商品减库存的实现方式同样关键，有限数量的商品在同一时刻被很多倍的请求同时来减库存，在大并发更新的过程中都要保证数据的准确性
* 高可用：秒杀时会在一瞬间涌入大量的流量，为了避免系统宕机，保证高可用，需要做好流量限制。

优化思路：

* 后端优化：将请求尽量拦截在系统上游
  * 限流：屏蔽掉无用的流量，允许少部分流量走后端。假设现在库存为 10，有 1000 个购买请求，最终只有 10 个可以成功，99% 的请求都是无效请求
    * **计数限流法**
      * 计数器 counter 来统计一段时间内请求的数量，并且在指定的时间之后重置计数器
    * **滑动窗口算法**
      * 滑动窗口算法是计数器算法的一种改进，将原来的一个时间窗口划分成多个时间窗口，并且不断向右滑动该窗口。流量经过滑动时间窗口算法整形之后，可以保证任意时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑，可以部分解决上面提到的临界突发流量问题。对比固定时间窗口限流算法，滑动时间窗口限流算法的时间窗口是持续滑动的，并且除了需要一个计数器来记录时间窗口内接口请求次数之外，还需要记录在时间窗口内每个接口请求到达的时间点，对内存的占用会比较多。
    * **令牌桶法**
      * 接口限制 t 秒内最大访问次数为 n，则每隔 t/n 秒会放一个 token 到桶中
      * 桶内最多存放 b 个 token，如果 token 到达时令牌桶已经满了，那么这个 token 就会被丢弃
      * 接口请求会先从令牌桶中取 token，拿到 token 则处理接口请求，拿不到 token 则进行限流处理
  * **消峰：秒杀请求在时间上高度集中于某一个时间点，瞬时流量容易压垮系统，因此需要对流量进行削峰处理，缓冲瞬时流量，尽量让服务器对资源进行平缓处理**
  * **异步：将同步请求转换为异步请求，来提高并发量，本质也是削峰处理**
  * **利用缓存：**创建订单时，每次都需要先查询判断缓存，只有少部分成功的请求才会创建订单，因此可以将商品信息放在缓存中，**减少数据库查询**
  * **负载均衡**：利用Nginx等使用多个服务器并发处理请求，减少单个服务器压力。

* 防作弊优化
  * 隐藏秒杀接口：如果秒杀地址直接暴露，在秒杀开始前可能会被恶意用户来刷接口，因此需要在没到秒杀开始时间不能获取秒杀接口，只有秒杀开始了，才返回秒杀地址 url 和验证 MD5，用户拿到这两个数据才可以进行秒杀

* 解决超卖问题
  * 悲观锁虽然可以解决超卖问题，但是加锁的时间可能会很长，会长时间的限制其他用户的访问，导致很多请求等待锁，卡死在这里，如果这种请求很多就会耗尽连接，系统出现异常
  * 乐观锁默认不加锁，更失败就直接返回抢购失败，可以承受较高并发

# 线程安全

一个方法或者一个实例在同一时刻可以被多个线程安全地调用，不发生竞态条件则认为是线程安全的。当多个线程竞争同一资源时，如果对资源的访问顺序敏感，就称存在静态条件。

# 可重入

可以有多个线程并发使用，而不必担心数据错误，可以在任何时候被中断，稍后再继续运行，不会丢失数据。可重入性解决函数运行结果的确定性和可重复性。

## 区别

* 一个函数对于多个线程是可重入的，则这个函数是线程安全的
* 一个函数是线程安全的，但并不一定是可重入的，比如使用互斥锁实现的线程安全
* 可重入性要强于线程安全性

# IO复用

## select系统调用

* 用途：在一段指定的时间内，监听用户感兴趣的文件描述符上的可读，可写和异常等事件
* select API
  * int select(int nfds,fd_set* readfds,fd_set* writefds,fd_set* exceptfds,struct timeval* timeout);
* 
* 文件描述符就绪条件
  * 可读
    * 内核接收缓冲区中的字节数大于或等于其低水位标记
    * socket通信的对方关闭连接，此时对该socket的读操作将返回0
    * 监听socket上有新的连接请求
    * socket上有未处理的错误
  * 可写
    * 发送缓存区可用字节数大于或等于其低水位标记
    * socket的写操作被关闭
    * socket使用非阻塞connect连接成功或者失败（超时）之后
    * socket上有未处理的错误

## poll系统调用

用途：在指定时间内轮询一定数量的文件描述符，以测试其中是否有就绪者

int poll(struct pollfd* fds,nfds_t nfds,int timeout);

## epoll系列系统调用

* epoll使用一组函数来完成任务，而不是单个函数
* **epoll把用户关心的文件描述符上的事件放在内核里的一个事件表中，从而无须像select和poll那样每次调用都重复传入文件描述符集或事件集**
* int epoll_create(int size)
* int epoll_ctl(int epfd,int op,int fd,struct epoll_event *event)
* int epoll_wait(int epfd,struct epoll_event* events,int maxevents,int timeout);
* LT和ET模式
  * epoll对文件符的操作有两种模式：LT(电平触发)和ET(边沿触发)
    * LT:
      * 将此事件通知应用程序后，应用程序可以不立即处理该事件，下一次调用epoll_wait时,还会再此像应用程序通知该事件
    * ET：
      * 应用程序必须立即处理该事件，因为后续的epoll_wait不会再向应用程序通知这一事件。可以降低epoll事件被触发的次数
      * 

* 阻塞IO和非阻塞IO的理解
  * 阻塞和非阻塞是应用程序对设备文件访问的两种方式，阻塞方式下，设备文件不可访问，进程就休眠，当设备文件可访问时，唤醒进程；非阻塞方式下，设备文件不可访问时，进程可以继续执行

* EPOLLONESHOT事件
  * 在使用ET模式时，在读取完某个socket上的数据后开始处理这些数据，而在处理该数据过程中该socket上又有新数据可读，此时另外一个线程被唤醒来读取这些新的数据，于是就出现了两个线程同时操作一个socket的局面。
  * 注册EPOLLONESHOT事件后当一个线程在处理某个socket时不允许别的线程有机会操作该socket，处理完成之后重置这个事件，别的socket才有机会处理这个socket
* select、poll和epoll区别
  * 事件集合
    * select：用户通过三个参数分别传入感兴趣的可读、可写以及异常等事件
    * poll：统一处理所有事件类型
    * epoLL:统一处理所有事件类型，通过一个事件表直接管理用户感兴趣的所有事件。
  * 索引就绪文件描述符的时间复杂度
    * o(n),o(n),o(1)
  * 最大支持文件描述符
    * 一般有最大限制	65535	65535
  * 工作模式
    * LT	LT 支持ET高效模式

# epoll底层数据结构：双向链表和红黑树

* 红黑树存储所监控的文件描述符的节点数据，就绪链表存储就绪的文件描述符的节点数据；epoll_ctl将会添加新的描述符，首先判断是红黑树上是否有此文件描述符节点，如果有，则立即返回。如果没有， 则在树干上插入新的节点，并且告知内核注册回调函数。
* 当接收到某个文件描述符过来数据时，会产生一个中断，linux系统在中断程序中将该节点插入到就绪链表里面。
