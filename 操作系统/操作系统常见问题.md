# 操作系统的内存管理
操作系统的内存管理包括物理内存管理和虚拟内存管理物理内存管理包括交换与覆盖，分页管理，分段管理和段页式管理等；虚拟内存管理包括虚拟内存的概念，页面置换算法，页面分配策略等；

# 虚拟内存&物理内存
    虚拟内存是计算机系统内存管理的一种方式，每个进程创建加载的时候，会被分配一个虚拟地址空间，虚拟的意思是这个地址空间并不真正存在物理内存中，而实际上，它用了多少空间，操作系统就在物理内存上上划出多少空间给它，而且划出的物理内存也不一定是连续的。
    系统将虚拟内存空间分割成为多个块，每一块称为一页，类似的，物理内存被分割为大小相同的物理页，它们之间通过一种叫做页表的数据结构联系起来，页表存放着各个虚拟页的状态。进程要知道哪些虚拟内存地址上的数据在物理内存上，哪些不在，还有在物理内存上的哪里，这就需要用页表来记录。如果发现对应的数据不在物理内存中，则发生缺页异常，执行内存置换算法，将缺失的部分装入物理内存中并重新执行失败的指令。
    虚拟内存空间分为内核区和用户区，内核空间是受保护的，用户不能对该空间进行读写操作，内核空间中保存的是内存管理，进程管理，设备驱动管理的模块；用户空间保存的是堆空间，栈空间，共享库，代码段，未初始化全局变量，初始化全局变量，命令行参数，环境变量等。
# 使用虚拟内存的优点

1. 虚拟内存给内存的分配和释放带来方便
物理地址不连续的几块内存可以映射成虚拟地址连续的一块内存，比如要用malloc分配一块很大的内存空间，虽然有足够多的空闲物理内存，却没有足够大的连续空闲内存，这是就可以分配多个不连续的物理页面而映射到连续的虚拟地址空间
2. 虚拟内存管理实现读写内存的安全性
物理内存本身是不限制访问的，任何地址都可以读写，而现代操作系统需要实现不同的页面具有不同的访问权限，例如只读的数据等等，可以通过CPU模式和MMU的内存保护机制实现。
3. 虚拟内存管理能够让每个进程都有独立的地址空间，这样使得任何一个进程执行错误指令或恶意代码导致的的非法内存访问都不会意外改写其他进程的数据，不会影响其他进程的运行，从而保证整个系统的稳定性。
4. 一个系统如果同时运行着很多进程，为各进程分配的内存之和可能会大于实际可用的物理内存，虚拟内存使得这种情况下各进程仍然能够正常运行。
# 虚拟内存置换算法

* 主要目标是使页面置换频率最低（也可以说缺页率最低）
* 最佳(Optimal)置换算法
  * 所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。
* 先进先出(FIFO)页面置换算法：
  * 选择换出的页面是最先进入的页面，该算法会将那些经常被访问的页面换出，导致缺页率升高。
* 最近最久未使用算法LRU
  * LRU 将最近最久未使用的页面换出。为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。 
* 第二次机会算法：
  先进先出的置换算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。
* 时钟（Clock）：    
  第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

# 用户态&内核态

* 用户态：用户态运行的进程可以直接读取用户程序的数据
* 内核态：内核态运行的进程或程序几乎可以访问计算机的任何资源，不受限制
* 两者最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态
* 用户态切换到内核态的3种方式：
  * 系统调用：这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现
  * 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常
  * 外围设备的中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。（比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。）

# 缺页中断

* 在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。
* 缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：
    1. 保护CPU现场
    2. 分析中断原因
    3. 转入缺页中断处理程序进行处理
    4. 恢复CPU现场，继续执行
* 但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：
    * 在指令执行期间产生和处理缺页中断信号
    * 一条指令在执行期间，可能产生多次缺页中断
    * 缺页中断返回的是，执行产生中断的一条指令，而一般的中断返回的是，执行下一条指令
* 
# 分页
虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。一个编译器在编译过程中会建立多个表，有的表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。
# 分段
分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。
# 段页式
程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。
# 分页与分段的比较

* 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段
* 地址空间的维度：分页是一维地址空间，分段是二维的
* 大小是否可以改变：页的大小不可变，段的大小可以动态改变
* 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

# 线程和进程
* 什么是进程
-进程是正在执行的程序，拥有代码和打开的文件资源、数据资源，独立的内存空间
* 什么是线程

  线程从属于进程，是程序的实际执行者，一个进程至少包含一个主线程，也可以有更多的子线程，线程拥有自己的栈空间。

* 区别

1. 拥有资源：进程是资源分配的基本单位，拥有独立的内存空间，独立的代码段，未初始化全局变量，初始化全局变量，堆，栈，动态库加载区，环境变量，命令行参数等资源，但是线程只拥有独立的栈空间，线程可以访问隶属进程的资源
2. 调度：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换【一个进程有多个线程】
3. 系统开销：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间，I/O 设备等，所付出的开销远大于创建或撤销线程时的开销；类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
4. 通信：线程间可以通过直接读写同一进程中共享内存中的数据，但是进程通信需要借助 IPC
* 优缺点
  **进程**：
  * 优点：1.每个进程相互独立，稳定性更好,方便内存管理和资源管理
* * 缺点：进程执行开销大，数据共享复杂。

**线程**

   * 优点：线程执行开销小，数据共享简单，cpu利用率高
   * 缺点：编程调试复杂，一个线程挂掉会导致整个进程挂掉

# 协程

协程，是一种比线程更加轻量级的存在，一个线程可以有多个协程。协程是程序员自己写的调度策略，通过协助而不是抢占来进行切换；进程和线程都是在内核态完成创建，切换和销毁，协程在用户态完成；协程的开销远小于线程。

#  孤儿进程 & 僵尸进程【怎么产生的？有什么危害？怎么去预防？】

* 一般进程，正常情况下：子进程由父进程创建，子进程再创建新的进程。父子进程是一个异步过程，父进程永远无法预测子进程的结束，所以，当子进程结束后，它的父进程会调用wait()或waitpid()取得子进程的终止状态，回收掉子进程的资源。
* 孤儿进程：父进程结束了，而它的一个或多个子进程还在运行，那么这些子进程就成为孤儿进程(father died)。子进程的资源由init进程回收
* 僵尸进程：子进程退出了，但是父进程没有用wait或waitpid去获取子进程的状态信息，回收进程。
* 危害：
    * 如果父进程不调用wait或waitpid的话，那么保留的信息就不会被释放，其进程号就会被一直占用，但是系统所能使用的进程号是有限的，如果大量产生僵死进程，将因没有可用的进程号而导致系统无法产生新的进程，这就是僵尸进程的危害
    * 孤儿进程是没有父进程的进程，它由init进程循环的wait()回收资源，init进程充当父进程。因此孤儿进程并没有什么危害
* 预防/解决方法：
    * 用两次fork()，然后使儿子进程直接退出，从而使孙子进程成为孤儿进程，进而由init进程负责清除这个孤儿进程
    * 通过信号机制，在处理函数中调用wait，回收资源

# 进程间的通信方式
* **管道**：
    * 只支持半双工通信（单向交替传输）；     
    * 只能在父子进程或者兄弟进程中使用。
    * 本质上是一个内核缓冲区，分为两部分，读端和写端，数据从写段流入，读端流出
    * int pipe(int fd[2])
      * fd[0]读端，fd[1]写端
* **命名管道**（FIFO）
    克服了管道没有名字的限制，具有管道所具有的功能外，还允许无亲缘关系进程间的通信，去除了管道只能在父子进程中使用的限制
    * 创建方式：
      * 命令: mkfifo 管道名
      * 函数： mkfifo 
* **信号**：
    信号是在软件层次上对中断机制的一种模拟，一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。
* **消息队列**：消息队列提供了从一个进程向另一个进程发送一个数据块的方法。
    * **相比于命名管道的优点：消息队列可以独立于读写进程存在** **避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法**；**读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。**
    *  **缺点** 使用消息队列进行进程间通信，可能会收到数据块最大长度的限制约束等。如果频繁的发生进程间的通信行为，那么进程需要频繁地读取队列中的数据到内存，相当于间接地从一个进程拷贝到另一个进程，这需要花费时间
* **共享内存** 共享内存可以很好解决拷贝消耗的时间。
    * 允许多个进程共享一个给定的存储区，不同进程可以及时看到对方进程中对共享内存中数据变更。因为数据不需要在进程之间复制，所以这是最快的一种 IPC
    * 共享内存需要依靠某种同步操作，如互斥锁和信号量等，需要使用信号量用来同步对共享存储的访问。
    * 系统加载一个进程的时候，分配给进程的内存并不是实际物理内存，而是虚拟内存空间。可以让两个进程各自拿出一块虚拟地址空间，然后映射到相同的物理内存中，这样，两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了
    * 创建方式：mmap函数
* **信号量**：为了避免共享内存多进程竞争内存的问题（线程安全），使用信号量
    * 信号量的本质就是一个计数器，用来实现进程之间的互斥与同步，用于为多个进程提供对共享数据对象的访问，信号量也是进程之间的一种通信方式。
* **套接字**：套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。
# 进程状态

* 创建状态(new) ：进程在创建时需要申请一个空白PCB，向其中填写控制和管理进程的信息，完成资源分配。
* 就绪状态(ready)：进程已经准备好，已分配到所需资源，只要分配到CPU就能够立即运行
* 执行状态，进程正在处理器上上运行
* 阻塞状态(waiting) ：又正在执行的进程由于某些事件（I/O请求，申请缓存区失败）而暂时无法运行，进程受到阻塞。在满足请求时进入就绪状态等待系统调用
* 结束状态(terminated) ：进程结束，或出现错误，或被系统终止，进入终止状态。无法再执行
* 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
* 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态
* 挂起（换到外存）: 
    * 挂起就绪：是指进程被对换到辅存时的就绪状态，是不能被直接调度的状态，只有当主存中没有活跃就绪态进程，或者是挂起就绪态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活跃就绪。
# 进程的调度
不同环境的调度算法目标不同，因此需要针对环境来讨论调度算法。
一 批处理系统
    * 批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）
        * 先来先服务调度算法（FCFS）：
        * 每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。
        * 比较有利于长作业（进程），而不利于短作业（进程）  
        * 有利于CPU繁忙型作业（进程） ，而不利于I/O繁忙型作业（进程）     
        * 用于批处理系统，不适于分时系统     
        * 短进程优先调度算法 
        *  从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。
        *  对长作业不利，未考虑作业(进程)的紧迫程度，因而不能保证紧迫性作业(进程)会被及时处理    
        * 最短剩余时间优先 shortest remaining time next（SRTN）  
        * 最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。           
二 交互式系统

* 交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应
* 时间片轮转法：
    * 系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU分配给队首进程，并令其执行一个时间片。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。
    * 紧迫任务响应慢。   
* 多级反馈队列调度算法：
    * 设置多个就绪队列，并为各个队列赋予不同的优先级；该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。
    * 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度；当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；
    * 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行  
* 优先权调度算法：把处理机分配给就绪队列中优先权最高的进程
    * 非抢占式优先权算法：系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；
    *  优先权调度算法：系统把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。 
    *  这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中 
    三 实时系统
* 实时系统要求一个请求在一个确定时间内得到响应。分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。
# 同步和异步
* 同步需要等待（阻塞），异步无需等待（不阻塞）
* 同步：可以理解为在执行完一个函数或方法之后，一直等待系统返回值或消息，这时程序是出于阻塞的，只有接收到返回的值或消息后才往下执行其他的命令
    * 同步就是整个处理过程顺序执行，当各个过程都执行完毕，并返回结果。是一种线性执行的方式，执行的流程不能跨越。一般用于流程性比较强的程序，比如用户登录，需要对用户验证完成后才能登录系统。
* 异步：执行完函数或方法后，不必阻塞性地等待返回值或消息，只需要向系统委托一个异步过程，那么当系统接收到返回值或消息时，系统会自动触发委托的异步过程，从而完成一个完整的流程
    * 异步则是只是发送了调用的指令，调用者无需等待被调用的方法完全执行完毕，而是继续执行下面的流程。是一种并行处理的方式，不必等待一个程序执行完，可以执行其它的任务，比如页面数据加载过程，不需要等所有数据获取后再显示页
# 同步和互斥

* 进程同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系
* 进程互斥：多个进程在同一时刻只有一个进程能进入临界区。
* 线程同步是指线程之间所具有的一种制约关系，一个线程的执行依赖另一个线程的消息，当它没有得到另一个线程的消息时应等待，直到消息到达时才被唤醒。
* 线程互斥是指当有若干个线程都要使用某一共享资源时，任何时刻最多只允许一个线程去使用，其它要使用该资源的线程必须等待，直到占用资源者释放该资源。
# 线程同步

* 读写锁
* 信号量
* 互斥锁
* 临界区 
# 线程通信

* 使用事件机制
* 使用信号机制
* 使用全局变量
# 信号量&互斥量

* 信号量：重点在信号，是协调任务执行顺序的一种机制
* 互斥量：重点在互斥，是一种锁机制
**不同：**

1. 所有者不同：
信号量：一个任务可以只获取（释放）信号量。获取信号量的任务不必非得释放信号量，反之亦然；
互斥量：占有互斥量的任务负责释放互斥量；
2. 优先级反转问题
虽然二值信号量可以实现互斥量的功能（很多人这么用），但是信号量没有实现防止优先级反转的功能。互斥量可以使用优先级继承和天花板策略防止优先级反转。
# 进程同步
**1. 临界区**
对临界资源进行访问的那段代码称为临界区。
** 临界资源：一次只允许一个进程使用的资源。
**2. 信号量**
信号量（Semaphore）是一个整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

    * **down:** 
如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；

    * **up:**
对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作
如果信号量的取值只能为 0 或者 1，那么就成为了 互斥量（Mutex） ，0 表示临界区已经加锁，1 表示临界区解锁。
**3. 管程：**
管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。
管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。
管程引入了 **条件变量 以及相关的操作：wait() 和 signal() 来实现同步操作**。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

* 生产者-消费者问题

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。
`#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}`
* 哲学家进餐问题
条件：哲学家围绕圆桌吃饭，有两种交替活动，吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的筷子，并且一次只能拿起一支
死锁解法：所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其他哲学家吃完并释放自己手中的筷子，导致死锁。
为了防止死锁的发生可以设置两个条件：
`#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}`
* 必须同时拿起左右两根筷子；
* 只有在两个邻居都没有进餐的情况下才允许进餐。
* **读者-写者问题**
允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。

# 操作系统中堆和栈
* 操作系统的堆和栈是指对内存进行操作和管理的一些方式这和数据结构中的堆和栈是有区别的
* 栈：
    * **分配和释放**：栈也可以称之为栈内存是一个动态内存区域，由编译器/系统自动分配和释放。例如，声明在函数中一个局部变量，即int b，系统自动在栈中为变量b开辟空间
    * **内容**：栈存放函数的参数值，局部变量的值等。
    *操作方式* ：*其操作方式类似于数据结构中的栈*，满足：“先进后出”的原则存取，也就是位于栈内的元素，必须等到其上面（对应的地址为较低的地址）的数据或函数执行完成后，弹出后才可以进行下面的元素的操作
    * 速度：速度较快
    * 申请大小的限制：**栈是向低地址扩展的，是一块连续的内存的区域。栈顶的地址和栈的最大容量是系统预先规定好的**，如果申请的空间超过栈的剩余空间时，将提示overflow。因此，能从栈获得的空间较小。
* 堆：
    * 一般由程序员分配释放，并指明大小，**堆被程序申请使用的内存在被主动释放前一直有效。**堆需要由由程序员手动释放，不及时回收容易产生内存泄露。 程序结束时可能由操作系统回收。
    * 速度较慢
    * 内容：数组和对象
    * 与数据结构中的堆是不同的，**分配方式类似于链表**（空闲链表法），堆是向高地址扩展的数据结构，是不连续的内存区域，这是由于系统是用链表来存储空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。
* 区别
    * 空间分配：栈由操作系统自动分配释放；堆一般由程序员分配释放
    * 申请效率对比：栈使用一级缓存，被调用时通常处于存储空间中，调用后被立即释放；.堆使用二级缓存，生命周期与虚拟机的GC算法有关，调用速度相对较低。
    * 申请大小的限制：栈是向低地址扩展的数据结构，是一块连续的内存的区域；堆是向高地址扩展的数据结构，是不连续的内存区域
# 栈比堆快的原因
栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。
# 链接
在Unix系统上，由编译器把源文件转换为目标文件的大致过程如下：
![15aa8e5204968cb42ceb9b3369151073.png](en-resource://database/1206:1)
* 预处理阶段：处理以#开头的预处理命令；
* 编译阶段：翻译成汇编文件；
* 汇编阶段：将汇编文件翻译成可重定位目标文件；
* 链接阶段：将可重定位目标和单独预编译好的目标文件进行合并，得到最终的可执行目标文件。
# 静态链接
静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

* 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
* 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。
# 动态链接
静态库有以下两个问题：
* 当静态库更新时那么整个程序都要重新进行链接；
* 对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。
共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。

* 它具有以下特点：在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
* 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。

# 目标文件

* 可执行目标文件：可以直接在内存中执行；
* 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
* 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

# 死锁
是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进
* 死锁产生的原因
    * 多个进程竞争资源
    * 进程间推进顺序不当
    死锁产生的必要条件（怎么检测死锁，解决死锁问题）
* 死锁产生的必要条件：
 1. 互斥条件，在任何时刻一个资源只能被一个进程使用 
 2. 拥有和请求（请求和保持条件），已经得到某个资源的进程可以再请求新的资源。 
3. 不可剥夺:已经分配给进程的资源不能被抢占，而只能被显式释放
4. 循环等待:系统中有两个或多个的进程组成一条循环，该循环中的每个进程都等待着另一个进程占有的资源

# 处理方法
## 死锁检测与死锁恢复
不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复

* 死锁检测
1. 每种类型一个资源的死锁检测
![baa8defc1c26de24f34207afb7248897.png](en-resource://database/1208:1)
上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

* 死锁恢复
    * 打破互斥条件。即允许进程同时访问某些资源。但是，有的资源是不允许被同时访问的，像打印机等等，这是由资源本身的属性所决定的。所以，这种办法并无实用价值。
    *  破坏占有和等待条件，一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。 
    *  破坏不可抢占条件
    *  破坏环路等待，给资源统一编号，进程只能按编号顺序来请求资源。

# 死锁避免
定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。
# 单个资源的银行家算法
作用：算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。
* 单个资源的银行家算法
![bc8f29d05ae51d382e5e833f1318b161.png](en-resource://database/1210:1)
上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。
# 多个银行家算法
![06fb0473cf23f9ef0e7dea0d0025e159.png](en-resource://database/1212:1)
上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。
检查一个状态是否是安全的算法如下：‘
* 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
* 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
* 重复以上两步，直到所有进程都标记为终止，则状态时安全的。
如果一个状态不是安全的，需要拒绝进入这个状态。

#  同一个进程内的线程会共享什么资源？

* 该进程的地址空间
* 全局变量
* 堆空间
# C++线程同步的四种方式（Windows）

# 线程之间的通信方式有哪些

* 使用全局变量
* 使用信号机制
* 使用事件

# 多进程多线程的区别和选择
![c8709d5ca40ee670372a2a0c58a26d83.png](en-resource://database/1214:2)

* 需要频繁创建和销毁的优先用线程
* 需要进行大量计算的优先使用线程
* 强相关处理的用线程，弱相关处理的用进程
* 可能要扩展到多机分布的用进程，多核分布的用线程
* 都满足要求的情况下，用最熟悉最拿手的方式
# 说一下PCB/说一下进程地址空间/
PCB就是进程控制块，是操作系统中的一种数据结构，用于表示进程状态，操作系统通过PCB对进程进行管理。
PCB中包含有：进程标识符，处理器状态，进程调度信息，进程控制信息
进程地址空间内有：
* 代码段text：存放程序的二进制代码
* 初始化的数据Data：已经初始化的变量和数据
* 初始化的数据Data：已经初始化的变量和数据
* 栈
* 堆
# 什么是饥饿
饥饿是由于资源分配策略不公引起的，当进程或线程无法访问它所需要的资源而不能继续执行时，就会发生饥饿现象。